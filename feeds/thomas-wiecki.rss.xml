<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>While My MCMC Gently Samples - Thomas Wiecki</title><link>https://twiecki.io/</link><description>Bayesian modeling, Data Science, and Python</description><lastBuildDate>Tue, 23 Feb 2021 10:00:00 -0500</lastBuildDate><item><title>Introducing PyMC Labs: Saving the World with Bayesian Modeling</title><link>https://twiecki.io/blog/2021/02/23/intro_pymc_labs/</link><description>&lt;p&gt;After I left Quantopian in 2020, something interesting happened: various companies contacted me inquiring about
consulting to help them with their PyMC3 models.&lt;/p&gt;
&lt;p&gt;Usually, I don't hear how people are using &lt;a href="https://docs.pymc.io/"&gt;PyMC3&lt;/a&gt; -- they mostly show up on
&lt;a href="https://github.com/pymc-devs/pymc3"&gt;GitHub&lt;/a&gt; or &lt;a href="https://discourse.pymc.io/"&gt;Discourse&lt;/a&gt; when something isn't working
right. So, hearing about all these …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 23 Feb 2021 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2021-02-23:/blog/2021/02/23/intro_pymc_labs/</guid><category>misc</category></item><item><title>Computational Psychiatry: Combining multiple levels of analysis to understand brain disorders - PhD thesis</title><link>https://twiecki.io/blog/2019/03/15/computational_psychiatry_thesis/</link><description>&lt;p&gt;I noticed that as my personal website at my former university went down that my PhD thesis could not be found anywhere, so I'm posting it here.&lt;/p&gt;
&lt;p&gt;During my PhD I explored how machine learning and computational modeling of the brain can be used to improve our understanding, and diagnostics …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Fri, 15 Mar 2019 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2019-03-15:/blog/2019/03/15/computational_psychiatry_thesis/</guid><category>misc</category></item><item><title>My foreword to "Bayesian Analysis with Python, 2nd Edition" by Osvaldo Martin</title><link>https://twiecki.io/blog/2019/01/21/foreword_bayesian_analysis_with_python/</link><description>&lt;p&gt;When &lt;a href="https://twitter.com/aloctavodia"&gt;Osvaldo&lt;/a&gt; asked me to write the foreword to his new book I felt honored, excited, and a bit scared, so naturally I accepted. What follows is my best attempt to convey what makes probabilistic programming so exciting to me. Osvaldo did a great job with the book, it is …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 21 Jan 2019 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2019-01-21:/blog/2019/01/21/foreword_bayesian_analysis_with_python/</guid><category>misc</category></item><item><title>Using Bayesian Decision Making to Optimize Supply Chains</title><link>https://twiecki.io/blog/2019/01/14/supply_chain/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2019 &lt;a href="https://twitter.com/twiecki"&gt;Thomas Wiecki&lt;/a&gt; &amp;amp; &lt;a href="https://twitter.com/canyon289"&gt;Ravin Kumar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One big problem I often observe with data science is that it often falls short of having a true impact on the bottom line of the business. The reasons for this are manifold but I firmly believe that Bayesian modeling solves many of them …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 14 Jan 2019 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2019-01-14:/blog/2019/01/14/supply_chain/</guid><category>misc</category></item><item><title>Hierarchical Bayesian Neural Networks with Informative Priors</title><link>https://twiecki.io/blog/2018/08/13/hierarchical_bayesian_neural_network/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2018 by Thomas Wiecki&lt;/p&gt;
&lt;p&gt;Imagine you have a machine learning (ML) problem but only small data (&lt;em&gt;gasp&lt;/em&gt;, yes, this does exist). This often happens when your data set is nested -- you might have many data points, but only few per category. For example, in ad-tech you may want predict …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 13 Aug 2018 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2018-08-13:/blog/2018/08/13/hierarchical_bayesian_neural_network/</guid><category>misc</category></item><item><title>An intuitive, visual guide to copulas</title><link>https://twiecki.io/blog/2018/05/03/copulas/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2018 by Thomas Wiecki&lt;/p&gt;
&lt;p&gt;People seemed to enjoy my &lt;a href="https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/"&gt;intuitive and visual explanation of Markov chain Monte Carlo&lt;/a&gt; so I thought it would be fun to do another one, this time focused on copulas.&lt;/p&gt;
&lt;p&gt;If you ask a statistician what a copula is they might say "a copula is …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Thu, 03 May 2018 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2018-05-03:/blog/2018/05/03/copulas/</guid><category>misc</category></item><item><title>What's new in PyMC3 3.1</title><link>https://twiecki.io/blog/2017/07/05/new-in-pymc3-31/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We recently released &lt;a href="https://github.com/pymc-devs/pymc3/blob/master/RELEASE-NOTES.md#pymc3-31-june-23-2017"&gt;PyMC3 3.1&lt;/a&gt; after the first stable 3.0 release in January 2017. You can update either via &lt;code&gt;pip install pymc3&lt;/code&gt; or via &lt;code&gt;conda install -c conda-forge pymc3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A lot is happening in PyMC3-land. One thing I am particularily proud of is the developer community we have …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Wed, 05 Jul 2017 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2017-07-05:/blog/2017/07/05/new-in-pymc3-31/</guid><category>misc</category></item><item><title>Random-Walk Bayesian Deep Networks: Dealing with Non-Stationary Data</title><link>https://twiecki.io/blog/2017/03/14/random-walk-deep-net/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Download the NB: &lt;a href="https://github.com/twiecki/WhileMyMCMCGentlySamples/blob/master/content/downloads/notebooks/random_walk_deep_net.ipynb"&gt;https://github.com/twiecki/WhileMyMCMCGentlySamples/blob/master/content/downloads/notebooks/random_walk_deep_net.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(c) 2017 by &lt;a href="https://twitter/twiecki"&gt;Thomas Wiecki&lt;/a&gt; -- &lt;a href="https://quantopian.com"&gt;Quantopian Inc.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Most problems solved by Deep Learning are stationary. A cat is always a cat. The rules of Go have remained stable for 2,500 years, and will likely …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 14 Mar 2017 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2017-03-14:/blog/2017/03/14/random-walk-deep-net/</guid><category>misc</category></item><item><title>Why hierarchical models are awesome, tricky, and Bayesian</title><link>https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2017 by Thomas Wiecki&lt;/p&gt;
&lt;p&gt;Hierarchical models are underappreciated. Hierarchies exist in many data sets and modeling them appropriately adds a boat load of statistical power (the common metric of statistical power). I provided an introduction to hierarchical models in a &lt;a href="https://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/"&gt;previous blog post: Best Of Both Worlds: Hierarchical Linear …&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Wed, 08 Feb 2017 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2017-02-08:/blog/2017/02/08/bayesian-hierchical-non-centered/</guid><category>misc</category></item><item><title>Bayesian Deep Learning Part II: Bridging PyMC3 and Lasagne to build a Hierarchical Neural Network</title><link>https://twiecki.io/blog/2016/07/05/bayesian-deep-learning/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2016 by Thomas Wiecki&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Recently, I blogged about &lt;a href="https://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/"&gt;Bayesian Deep Learning with PyMC3&lt;/a&gt; where I built a simple hand-coded Bayesian Neural Network and fit it on a toy data set. Today, we will build a more interesting model using &lt;a href="https://lasagne.readthedocs.io/en/latest/"&gt;Lasagne&lt;/a&gt;, a flexible &lt;code&gt;Theano&lt;/code&gt; library for constructing various types of …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 05 Jul 2016 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2016-07-05:/blog/2016/07/05/bayesian-deep-learning/</guid><category>misc</category></item><item><title>Bayesian Deep Learning</title><link>https://twiecki.io/blog/2016/06/01/bayesian-deep-learning/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Variational-Inference:-Bayesian-Neural-Networks"&gt;Variational Inference: Bayesian Neural Networks&lt;a class="anchor-link" href="#Variational-Inference:-Bayesian-Neural-Networks"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;(c) 2016-2018 by Thomas Wiecki, updated by Maxim Kochurov&lt;/p&gt;
&lt;p&gt;Original blog post: &lt;a href="https://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/"&gt;https://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Current-trends-in-Machine-Learning"&gt;Current trends in Machine Learning&lt;a class="anchor-link" href="#Current-trends-in-Machine-Learning"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;There are currently three big trends in machine learning: &lt;strong&gt;Probabilistic Programming&lt;/strong&gt;, &lt;strong&gt;Deep Learning&lt;/strong&gt; and "&lt;strong&gt;Big Data&lt;/strong&gt;". Inside of PP …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Wed, 01 Jun 2016 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2016-06-01:/blog/2016/06/01/bayesian-deep-learning/</guid><category>misc</category></item><item><title>MCMC sampling for dummies</title><link>https://twiecki.io/blog/2015/11/10/mcmc-sampling/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;When I give talks about probabilistic programming and Bayesian statistics, I usually gloss over the details of how inference is actually performed, treating it as a black box essentially. The beauty of probabilistic programming is that you actually don't &lt;em&gt;have&lt;/em&gt; to understand how the inference works in order to build …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 10 Nov 2015 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2015-11-10:/blog/2015/11/10/mcmc-sampling/</guid><category>misc</category></item><item><title>A modern guide to getting started with Data Science and Python</title><link>https://twiecki.io/blog/2014/11/18/python-for-data-science/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Python has an extremely rich and healthy ecosystem of data science tools. Unfortunately, to outsiders this ecosystem can look like a jungle (cue snake joke). In this blog post I will provide a step-by-step guide to venturing into this PyData jungle.&lt;/p&gt;
&lt;p&gt;What's wrong with the many lists of PyData packages …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 18 Nov 2014 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2014-11-18:/blog/2014/11/18/python-for-data-science/</guid><category>misc</category></item><item><title>The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3</title><link>https://twiecki.io/blog/2014/03/17/bayesian-glms-3/</link><description>&lt;p&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="The-best-of-both-worlds:-Hierarchical-Linear-Regression-in-PyMC3"&gt;The best of both worlds: Hierarchical Linear Regression in PyMC3&lt;a class="anchor-link" href="#The-best-of-both-worlds:-Hierarchical-Linear-Regression-in-PyMC3"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) Thomas Wiecki &amp;amp; Danne Elbers 2020&lt;/p&gt;
&lt;p&gt;The power of Bayesian modelling really clicked for me when I was first introduced to hierarchical modelling. In this blog post we will highlight the advantage of using hierarchical Bayesian modelling as opposed to …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 17 Mar 2014 09:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2014-03-17:/blog/2014/03/17/bayesian-glms-3/</guid><category>misc</category></item><item><title>Easily distributing a parallel IPython Notebook on a cluster</title><link>https://twiecki.io/blog/2014/02/24/ipython-nb-cluster/</link><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Have you ever asked yourself: "Do I want to spend 2 days adjusting this analysis to run on the cluster and wait 2 days for the jobs to finish or do I just run it locally with no extra work and just wait a week."&lt;/p&gt;
&lt;p&gt;If so, this blog post …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 24 Feb 2014 09:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2014-02-24:/blog/2014/02/24/ipython-nb-cluster/</guid><category>misc</category></item><item><title>Animating MCMC with PyMC3 and Matplotlib</title><link>https://twiecki.io/blog/2014/01/02/visualizing-mcmc/</link><description>&lt;p&gt;Here's the deal: I used &lt;a href="https://github.com/pymc-devs/pymc"&gt;PyMC3&lt;/a&gt;,
&lt;a href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt;, and &lt;a href="http://jakevdp.github.io/"&gt;Jake Vanderplas'&lt;/a&gt;
&lt;a href="https://github.com/jakevdp/JSAnimation"&gt;JSAnimation&lt;/a&gt; to create
javascript animations of three MCMC sampling algorithms --
&lt;a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis-Hastings&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Slice_sampling"&gt;slice sampling&lt;/a&gt; and &lt;a href="http://arxiv.org/abs/1111.4246"&gt;NUTS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I like visualizations because they provide a good intuition for how
the samplers work and what problems they can run into.&lt;/p&gt;
&lt;p&gt;You can download the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Thu, 02 Jan 2014 09:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.io,2014-01-02:/blog/2014/01/02/visualizing-mcmc/</guid><category>misc</category></item><item><title>Hammer time: Nailing the emcee ensemble sampler onto PyMC</title><link>https://twiecki.io/blog/2013/09/23/emcee-pymc/</link><description>&lt;p&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;tl;dr: I hacked the &lt;a href="http://dan.iel.fm/emcee/"&gt;&lt;code&gt;emcee&lt;/code&gt;--The MCMC-Hammer&lt;/a&gt; ensemble sampler to work on &lt;code&gt;PyMC&lt;/code&gt; models.&lt;/p&gt;
&lt;h2 id="Motivation"&gt;Motivation&lt;a class="anchor-link" href="#Motivation"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://pymc-devs.github.io/pymc/"&gt;&lt;code&gt;PyMC&lt;/code&gt;&lt;/a&gt; is an awesome Python module to perform Bayesian inference. It allows for flexible model creation and has basic MCMC samplers like &lt;a href="http://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis-Hastings&lt;/a&gt;. The upcoming PyMC3 will feature much fancier samplers like &lt;a href="http://en.wikipedia.org/wiki/Hybrid_Monte_Carlo"&gt;Hamiltonian-Monte Carlo …&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 23 Sep 2013 09:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2013-09-23:/blog/2013/09/23/emcee-pymc/</guid><category>misc</category></item><item><title>This world is far from Normal(ly distributed): Bayesian Robust Regression in PyMC3</title><link>https://twiecki.io/blog/2013/08/27/bayesian-glms-2/</link><description>&lt;p&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Author: Thomas Wiecki&lt;/p&gt;
&lt;p&gt;This tutorial first appeard as a post in small series on Bayesian GLMs on my blog:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://twiecki.github.com/blog/2013/08/12/bayesian-glms-1/"&gt;The Inference Button: Bayesian GLMs made easy with PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/"&gt;This world is far from Normal(ly distributed): Robust Regression in PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/"&gt;The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3 …&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 27 Aug 2013 12:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2013-08-27:/blog/2013/08/27/bayesian-glms-2/</guid><category>misc</category></item><item><title>The Inference Button: Bayesian GLMs made easy with PyMC3</title><link>https://twiecki.io/blog/2013/08/12/bayesian-glms-1/</link><description>&lt;p&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Author: Thomas Wiecki&lt;/p&gt;
&lt;p&gt;This tutorial appeared as a post in a small series on Bayesian GLMs on my blog:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://twiecki.github.com/blog/2013/08/12/bayesian-glms-1/"&gt;The Inference Button: Bayesian GLMs made easy with PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/"&gt;This world is far from Normal(ly distributed): Robust Regression in PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/"&gt;The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3 …&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 12 Aug 2013 07:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.io,2013-08-12:/blog/2013/08/12/bayesian-glms-1/</guid><category>misc</category></item></channel></rss>